\documentclass[a4paper,10pt]{article}
%%%
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}
%%%

\title{Implementation of a standalone Galaxy instance for the creation of re-usable bioinformatics processing pipelines}
\author{Daniel J. Shea}
\date{August 16th, 2014}

\begin{document}
\maketitle
\pagebreak
\section{Introduction}
Using yeast (Schizosaccharomyces Pombe and Saccharomyces Cervisiae) as our model organism, our research is conducted into understanding the biological processes underlying the formation, function, and epigenetic inheritance of silent chromatin domains.  Three major areas of research are related to RNAi-mediated assembly of heterochromatin, SIR-mediated assembly of silent chromatin, and the regulation of recombination within the ribosomal DNA repeats.  In order to improve the efficiency of data analysis via re-usable bioinformatics pipelines and to encourage collaboration and software re-use within the lab, we have chosen to implement a local instance of the Galaxy Project's open source web-based platform.
\subsection{Heterochromatin's role in the silencing of genes}
The physical organization of DNA in eukaryotes plays a role in the levels of genetic expression by restricting the physical access of transcriptional machinery to various regions of an organism's genome.  The organization of DNA is structured around histones, octamers composed of highly conserved proteins, H2A, H2B, H3, and H4.  These proteins form heterodimers H2A/H2B and H3/H4, respectively, that then further form tetramers.  In turn, these tetramers then combine to form an octamer that is referred to as a histone.  DNA winds around these histones forming a nucleosome, with small segments of DNA, referred to as linker DNA, between them.  Structured around this basic organization of DNA are regions of tightly or loosely condensed chromatin, referred to as heterochromatin and euchromatin respectively.  Heterochromatin plays a functional role in gene silencing through the physical restriction of access to DNA by transcriptional machinery involved in transcribing DNA into messenger RNA (mRNA).
\subsection{Benefits derived from the implementation of Galaxy within the lab}
Galaxy is an open, web-based platform for the analysis of data intensive biological research.  It provides an interactive and readily accessible web interface to many of the commonly used bioinformatics tools available today.  Computational pipelines may be constructed from within the web interface and then shared between users.  Workflows are accessible via the workflow editor, which allows for the visualization and editing of processing pipelines.  These workflows may then be abstracted for application to multiple data sets, and the workflows themselves can be shared between Galaxy users through the Galaxy web interface.  This allows researchers within our environment to compose analytical workflows that may then be re-used or re-purposed by other collaborators in the lab with minimal effort.
\section{Computational server architectural overview}
Our computational server, chromosome.med.harvard.edu, serves as the platform on which we run our Galaxy instance.  It should be noted however, that a local galaxy instance can be run on hardware with relatively modest specifications.  Depending upon the data sets and types of analyses performed, you may be constrained by the available amount RAM on your server when dealing with particularly large data sets or application of computationally intensive analysis such as attempting to perform de novo assembly.  The table below details the hardware configuration for chromosome.
\subsection{Hardware Configuration}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|r|p{.8\linewidth}|}
\hline
\multicolumn{2}{|c|}{\textbf{chromosome.med.harvard.edu}}\\
\hline
\textbf{CPU:} & (2) Intel(R) Xeon(R) CPU  X5660  @ 2.80GHz, 6 Physical cores (12 Hyper-threaded)\\
\hline
\textbf{Memory:} & (18) 4GB DDR3-800 DIMMs for a total of 72GB\\
\hline
\textbf{Disk:} & (8) 1.817 TB SATA Drives configured as a RAID-6 array, providing 10.908TB of usable space\\
\hline
\textbf{OS:} & Ubuntu 12.04.4 LTS\\
\hline
\end{tabular}
\section{Galaxy Architectural Overview}
Galaxy provides default web server and local database storage for standalone instances.  Depending on the use case, it is advised to reconfigure the instance to make use of more robust data storage and/or web server solutions.  For our particular instance, we are currently utilizing a postgresql database as our back-end storage.  Given the relatively small number of users within our lab utilization of nginx or apache as a web server, however, should the internal webserver prove to pose a bottleneck at a later date, the existing configuration may be migrated to nginx to take advantage of caching functionality to serve the static portions of the Galaxy web site.  By default, sqlite internal database files are utilized for the storage of data and computational workflows.  This proved promblematic as our anticipated data sets were determined to quickly tax a small flat file database system such as sqlite.  Therefore, we opted to create a postgresql database wherein to store all of our data.  Details on how to accomplish this are detailed below in the database subsection.

User authentication and role based authentication are handled by the Galaxy server itself.  Larger installations with access to a centralized user identification management system such as LDAP or kerberos may be able to take advantage of identity caching through configuration of login caching and forwarding via apache or nginx.  Attempts to tie our local instance to existing LDAP authentication mechanisms proved to break the existing administrative functionality of the server.  These issues were raised with the development team of the Galaxy Project and it is currently being assessed as a possible feature request by Galaxy development team.

Below, we outline the necessary steps undertaken to install and configure our Galaxy standalone instance using the native python based web server and a postgresql back-end database for the storage of our data.
\subsection{Galaxy and postgresql installation procedures}
To install Galaxy we can retrieve the latest stable version from the mercurial repository.  In order to do this, we must have the mercurial package installed.  \textit{(\textbf{Note:} Since we are using Ubuntu server as our linux distribution, we will demonstrate how to do this using the Ubuntu package management tools.  Please refer to your operating system's package management documentation if you are using a different distribution of linux.)}
\\\\
\fcolorbox{gray}{Lavender}{
\parbox{\linewidth}{
\begin{itemize}
\item[] \texttt{sudo apt-get install mercurial}
\end{itemize}
}}

\vspace{1em}
Once mercurial is installed we may then install the latest stable Galaxy from the mercurial repository.
\\\\
\fcolorbox{gray}{Lavender}{
\parbox{\linewidth}{
\begin{itemize}
\item[] \texttt{hg clone https://bitbucket.org/galaxy/galaxy-dist/}
\item[] \texttt{cd galaxy-dist}
\item[] \texttt{hg update stable}
\end{itemize}
}}

\vspace{1em}
This is enough to configure a simple standalone Galaxy instance utilizing the internal sqlite database and python webserver.  You can test the installation by attempting to start Galaxy by running the following command from within the \texttt{galaxy-dist} directory.
\\\\
\fcolorbox{gray}{Lavender}{
\parbox{\linewidth}{
\begin{itemize}
\item[] \texttt{sh run.sh}
\end{itemize}
}}

\vspace{1em}
The initial run of Galaxy will pull necessary python .egg files and start a local instance of the Galaxy server.  We can now shut down the test instance as we will next install postgresql and configure Galaxy to rely on the external database as our back-end data store for all of our research data.  Shutdown of Galaxy may be performed by issuing a \texttt{Ctrl-c} in the terminal where \texttt{sh run.sh} was instantiated.

To configure postgresql we will need to install the postgresql package.
\\\\
\fcolorbox{gray}{Lavender}{
\parbox{\linewidth}{
\begin{itemize}
\item[] \texttt{sudo apt-get install postgresql}
\end{itemize}
}}

\vspace{1em}
Further details regarding the configuration of postgresql may be obtained in your operating system's system administration documentation, or by accessing postgresql documentation available \href{http://www.postgresql.org/}{online}.  Once the database software is installed, we must create a database owned by the user id that will run the Galaxy server.  In our case the user id is \texttt{galaxy}.  \textit{(\textbf{Note:} The name of the database user created in postgresql should match whatever username is chosen.)}  Since the Galaxy platform controls its own schema within the database, we need to ensure that our galaxy user has the appropriate permissions and ownership of the the database for table creation.  This is controlled through the postgresql configuration and instructions on how to assign roles and permissions to a postgresql user may be referenced in the postgresql documentation.

\subsection{Galaxy standalone instance configuration}
Once a database has been created and we have created both the relevant galaxy user in the operating system and in the database authentication systems, we can begin to configure Galaxy for use with an external database.
Galaxy stores its relevant configuration information in a file located at the top-level directory \texttt{galaxy-dist} within a file named \texttt{universe\_wsgi.ini}.

First we should ensure that the Galaxy server will be accessible from external interfaces if we are planning on setting up a web accessible standalone instance.  This can be done by making the following change to the host entry within \texttt{universe\_wsgi.ini}:
\\\\
\fcolorbox{gray}{Lavender}{
\begin{minipage}{\textwidth}
\texttt{\# The address on which to listen.  By default, only listen to}\\
\texttt{\# localhost (Galaxy will not be accessible over the network).}\\
\texttt{\# Use '0.0.0.0' to listen on all available network interfaces.}\\
\texttt{\# host = 127.0.0.1}\\
\texttt{host = 0.0.0.0}
\end{minipage}
}

\section{Setting up a Data Library in Galaxy}
Galaxy allows for the configuration of data libraries in order to share data files.  The benefit of a data library is that access control may be permissioned on a user or group basis, if necessary.  Furthermore, data stored in a data library is only stored once within the database.  When users import data from a data library, a pointer to the original data is passed.  This reduces disk utilization on the server and circumvents duplication of large data sets shared among multiple users.

We have implemented a Data Library within Galaxy as a centralized repository for all of our laboratory's publicly published data.  This enables new researcher's to quickly make use of relevant available data, along with maintaining NCBI GEO and SRA accession identifiers should further relevant data not originating from the lab be required.  This data is then readily applicable and already in the proper data formats applicable to existing bioinformatics workflows published within our Galaxy instance.
\subsection{Example Data Library creation}
\section{Galaxy workflow creation}
Workflows are created either by extracting a workflow from an existing analysis, or by building a workflow within the workflow editor.  Workflows allow for the creation of a generalized pipeline for the processing of biological data using the many tools installed in the Galaxy tool shed.  This approach utilizes a graphical flowchart detailing the inputs and outputs derived from each tool.  Individual tool's outputs may be connected to the inputs of subsequent tools, forming a data pipeline.  These workflows may then be saved and shared with other users of the Galaxy platform.

Workflows are modeled after data flow diagrams found in software engineering, whereby an input data set is transformed through a series of applied functions, resulting in output derived from the series of transformations applied to the data in the model.  This allows for an abstract representation of the analysis to be performed on a type of data input which which result in data output of a specific format.  Further complex analysis can then be derived by chaining relatively simple workflows to construct larger, more complex analytical pipelines.  Presented below is an example, illustrating the workflow creation process, utilizing the workflow editor.
\subsection{Example workflow}
\section{Conclusions}
\end{document}